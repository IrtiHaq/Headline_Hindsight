{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRS9dPGITQx+8a44i7H8Tk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Headline Hindsight: Data Pre-Processing and NMF Model\n","Irti Haq Irtihaq@uw.edu BC | Andrew Simon simona6@uw.edu BC | Jeleen Limawan je0110@uw.edu AB | Joeph Rafael joephr@uw.edu AD\n","\n"],"metadata":{"id":"471YYHRy3Xer"}},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8Tv3OUf9xGb","executionInfo":{"status":"ok","timestamp":1684297729396,"user_tz":420,"elapsed":26234,"user":{"displayName":"Irti Haq","userId":"17287341463040515023"}},"outputId":"1ff1af35-fad7-4650-9ed7-1bea98b3742d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52dcFh90zQTh"},"outputs":[],"source":["#@title Imports\n","!pip install contractions\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import NMF\n","\n","import string \n","import nltk\n","from nltk.corpus import stopwords\n","import contractions\n"]},{"cell_type":"code","source":["# Load Data\n","news_df = pd.read_csv('all-the-news-headlines.csv').drop(['section', 'Unnamed: 0'], axis = 1).reset_index(drop=True)\n","news_df"],"metadata":{"id":"3Vez1sKi3ur3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Pre-Proccessing The Dataset\n","\n","# List of Publications are going to be Removed Because They Are more Lifestyle News Oriented\n","pubs_to_remove = ['Gizmodo', 'Hyperallergic', 'Mashable', 'New Republic', \n","                  'New Yorker', 'People', 'Refinery 29', 'TMZ', 'TechCrunch',\n","                  'The Verge', 'Vice', 'Wired']\n","\n","# Remote Articles without Publication Name\n","news_df['publication'].replace('', np.nan, inplace=True)\n","news_df.dropna(subset=['publication'], inplace=True)\n","\n","# Remote Articles without Headlines\n","news_df['title'].replace('', np.nan, inplace=True)\n","news_df.dropna(subset=['title'], inplace=True)\n","\n","# Calc Word Count of Headlines\n","news_df['word_count'] = news_df['title'].str.split().str.len()\n","\n","# Remove Article Where Headline is Less than 2 words\n","news_df = news_df[news_df['word_count'] > 2]\n","news_df = news_df.drop('word_count', axis=1)\n","\n","# Drop Lifestyle Publications and Reset Index\n","news_df = news_df[~news_df['publication'].isin(pubs_to_remove)].reset_index(drop=True)"],"metadata":{"id":"f5BCz4Hq3xxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Pre-Proccessing Headlines\n","\n","# Filling NA's\n","news_df = news_df.fillna('')\n","\n","# Make Headlines Lower Case & Removing Punctuation\n","news_df['title'] = news_df['title'].str.lower().apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n","\n","# Specifying Additional words\n","stop_words_add = news_df['publication'].str.split().explode().str.lower().unique().tolist()\n","stop_words_add.extend(['thehill','(cnn)','(reuters)', \n","                       'playerwatch', 'new',  'york', 'times', \n","                       'opinion', 'stockswall', 'snapshotwall',\n","                       'north', 'south'])\n","# Downloading Stopwords from NLTK\n","nltk.download('stopwords')\n","\n","# Saving only English Stopwords\n","all_stop_words = set(stopwords.words('english'))\n","\n","# Adding Additional Stopwords\n","all_stop_words.update(stop_words_add)\n","\n","\n","# Stop Word Remover Function\n","def stopword_remover(text):\n","    words = text.split()\n","    words = [word for word in words if word not in all_stop_words]\n","    return ' '.join(words)\n","\n","# Fixing and Replacing Contractions\n","news_df['title'] = news_df['title'].apply(lambda x: contractions.fix(x))\n","\n","# Removing Stop Words\n","news_df['title'] = news_df['title'].apply(stopword_remover)"],"metadata":{"id":"YuSm1yTo5EUk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684297771073,"user_tz":420,"elapsed":3559,"user":{"displayName":"Irti Haq","userId":"17287341463040515023"}},"outputId":"0d7492c3-99ce-4d47-96e1-e15fe4eaacd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["# Remove Additional Anomalous Rows\n","plus_remove = ['watch', 'trump', 'trump trump trump', 'coronavirus us', 'coronavirus', 'coronavirus 1', 'stocks stocks', 'winning numbers drawn ‘pick 3 day’ game', \n","     'winning numbers drawn ‘pick 4 day’ game', 'week', 'hills 1230 report inside mueller report', 'today state state', 'preview state', 'us america']\n","\n","news_df = news_df[~news_df['title'].isin(plus_remove)].reset_index(drop=True)"],"metadata":{"id":"9RtSc4ElyzA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving Pre-Proccessed Dataset as a Pickle File\n","news_df.to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/cleaned-all-the-news_smpl_270k.pkl\")"],"metadata":{"id":"qtBr-eWv7XTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Hyperparameter Tunning\n","# Number of Components Tunning \n","# Source: https://www.kaggle.com/code/rockystats/topic-modelling-using-nmf\n","\n","# For All Years\n","'''\n","import pandas as pd\n","import numpy as np\n","from sklearn.decomposition import NMF\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from gensim.models.coherencemodel import CoherenceModel\n","from gensim.corpora.dictionary import Dictionary\n","from gensim.models.nmf import Nmf\n","from collections import Counter\n","from operator import itemgetter\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","\n","from nltk.tokenize import TweetTokenizer\n","\n","def casual_tokenizer(text):\n","    tokenizer = TweetTokenizer()\n","    tokens = tokenizer.tokenize(text)\n","    return tokens\n","\n","# Use Gensim's NMF to get the best num of topics via coherence score\n","texts = news_df['title'].apply(casual_tokenizer)\n","\n","# Create a dictionary\n","# In gensim a dictionary is a mapping between words and their integer id\n","dictionary = Dictionary(texts)\n","\n","# Filter out extremes to limit the number of features\n","dictionary.filter_extremes(\n","    no_below=3,\n","    no_above=0.85,\n","    keep_n=5000\n",")\n","\n","# Create the bag-of-words format (list of (token_id, token_count))\n","corpus = [dictionary.doc2bow(text) for text in texts]\n","\n","# Create a list of the topic numbers we want to try\n","topic_nums = list(np.arange(5, 75 + 1, 5))\n","\n","# Run the nmf model and calculate the coherence score\n","# for each number of topics\n","coherence_scores = []\n","\n","for num in topic_nums:\n","    nmf = Nmf(\n","        corpus=corpus,\n","        num_topics=num,\n","        id2word=dictionary,\n","        chunksize=2000,\n","        passes=5,\n","        kappa=.1,\n","        minimum_probability=0.01,\n","        w_max_iter=300,\n","        w_stop_condition=0.0001,\n","        h_max_iter=100,\n","        h_stop_condition=0.001,\n","        eval_every=10,\n","        normalize=True,\n","        random_state=42\n","    )\n","    \n","    # Run the coherence model to get the score\n","    cm = CoherenceModel(\n","        model=nmf,\n","        texts=texts,\n","        dictionary=dictionary,\n","        coherence='c_v'\n","    )\n","    \n","    coherence_scores.append(round(cm.get_coherence(), 5))\n","\n","# Get the number of topics with the highest coherence score\n","scores = list(zip(topic_nums, coherence_scores))\n","best_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n","\n","# Plot the results\n","fig = plt.figure(figsize=(15, 7))\n","\n","plt.plot(\n","    topic_nums,\n","    coherence_scores,\n","    linewidth=3,\n","    color='#4287f5'\n",")\n","\n","plt.xlabel(\"Topic Num\", fontsize=14)\n","plt.ylabel(\"Coherence Score\", fontsize=14)\n","plt.title('Coherence Score by Topic Number - Best Number of Topics: {}'.format(best_num_topics), fontsize=18)\n","plt.xticks(np.arange(5, max(topic_nums) + 1, 5), fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","plt.show()\n","\n","'''\n","\n","# By Year\n","'''\n","import pandas as pd\n","import numpy as np\n","from sklearn.decomposition import NMF\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from gensim.models.coherencemodel import CoherenceModel\n","from gensim.corpora.dictionary import Dictionary\n","from gensim.models.nmf import Nmf\n","from collections import Counter\n","from operator import itemgetter\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","\n","from nltk.tokenize import TweetTokenizer\n","\n","def casual_tokenizer(text):\n","    tokenizer = TweetTokenizer()\n","    tokens = tokenizer.tokenize(text)\n","    return tokens\n","\n","\n","years = [2016, 2017, 2018, 2019, 2020]\n","\n","for year in years:\n","\n","    # Use Gensim's NMF to get the best num of topics via coherence score\n","    texts = news_df.loc[news_df['year'] == year, 'title'].apply(casual_tokenizer)\n","\n","    # Create a dictionary\n","    # In gensim a dictionary is a mapping between words and their integer id\n","    dictionary = Dictionary(texts)\n","\n","    # Filter out extremes to limit the number of features\n","    dictionary.filter_extremes(\n","        no_below=3,\n","        no_above=0.85,\n","        keep_n=5000\n","    )\n","\n","    # Create the bag-of-words format (list of (token_id, token_count))\n","    corpus = [dictionary.doc2bow(text) for text in texts]\n","\n","    # Create a list of the topic numbers we want to try\n","    topic_nums = list(np.arange(5, 75 + 1, 5))\n","\n","    # Run the nmf model and calculate the coherence score\n","    # for each number of topics\n","    coherence_scores = []\n","\n","    for num in topic_nums:\n","        nmf = Nmf(\n","            corpus=corpus,\n","            num_topics=num,\n","            id2word=dictionary,\n","            chunksize=2000,\n","            passes=5,\n","            kappa=.1,\n","            minimum_probability=0.01,\n","            w_max_iter=300,\n","            w_stop_condition=0.0001,\n","            h_max_iter=100,\n","            h_stop_condition=0.001,\n","            eval_every=10,\n","            normalize=True,\n","            random_state=42\n","        )\n","        \n","        # Run the coherence model to get the score\n","        cm = CoherenceModel(\n","            model=nmf,\n","            texts=texts,\n","            dictionary=dictionary,\n","            coherence='c_v'\n","        )\n","        \n","        coherence_scores.append(round(cm.get_coherence(), 5))\n","\n","    # Get the number of topics with the highest coherence score\n","    scores = list(zip(topic_nums, coherence_scores))\n","    best_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n","\n","    # Plot the results\n","    fig = plt.figure(figsize=(15, 7))\n","\n","    plt.plot(\n","        topic_nums,\n","        coherence_scores,\n","        linewidth=3,\n","        color='#4287f5'\n","    )\n","\n","    plt.xlabel(\"Topic Num\", fontsize=14)\n","    plt.ylabel(\"Coherence Score\", fontsize=14)\n","    plt.title('Coherence Score by Topic Number - Best Number of Topics: {}'.format(best_num_topics), fontsize=18)\n","    plt.xticks(np.arange(5, max(topic_nums) + 1, 5), fontsize=12)\n","    plt.yticks(fontsize=12)\n","\n","    plt.savefig('score' + str(year) + \".png\")\n","    plt.close()\n","'''\n","# Saved Plots Can Found Using this Link \n","#https://drive.google.com/drive/folders/1hfrEH970GetD0hsIQiAq-4uLzyfsO6si?usp=share_link"],"metadata":{"id":"Ruvyu_kj6U5V","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title NMF Modeling Function\n","\n","def nmf_by_filter (filt_news_df = news_df, publication_name=None, \n","                   year =None,\tmonth=None,\tday=None, nun_comp=10):\n","  '''\n","  runs NMF on a subset of the data based on the filters\n","  Importaint Make Sure to Run Pre-Proccessing and Cleaning\n","\n","  Args:\n","  - news_df\n","  - publication_name (string or list): Name of the publication\n","  - year (int)\n","  - month (int)\n","  - day (int)\n","  - nun_comp(int): Number of Topics\n","\n","  Returns:\n","  - A list of dataframes [word_score_by_topic_df, article_score_df, word_score_df]\n","  - word_score_by_topic: Word Score by Topic \n","  - article_score_df: Article Scores\n","  - word_score_df: Word Scores\n","  '''\n","\n","  # Checks to See If any Filters are Specified and Filters Dataset\n","  if isinstance(publication_name, str):\n","    publication_name = [publication_name]\n","\n","  if publication_name is not None:\n","    filt_news_df = filt_news_df[filt_news_df['publication'].isin(publication_name)]\n","  \n","  if year is not None:  \n","    filt_news_df = filt_news_df[filt_news_df['year'] == year]\n","  \n","  if month is not None:  \n","    filt_news_df = filt_news_df[filt_news_df['month'] == month]\n","  \n","  if day is not None:\n","    filt_news_df = filt_news_df[filt_news_df['day'] == day]\n","\n","  filt_news_df = filt_news_df.reset_index(drop=True)\n","  \n","  #TF-IDF matrix\n","  filt_vectorizer = TfidfVectorizer(max_df=0.80) # Might Want to tweak max_df <- Hyperparam\n","  filt_tf_idf = filt_vectorizer.fit_transform(filt_news_df['title'])\n","\n","  # Extract Feature Names\n","  filt_feature_names = filt_vectorizer.get_feature_names_out()\n","\n","  # Model\n","\n","  filt_model = NMF(init='nndsvd', n_components=nun_comp) # <- n_components Hyperparam\n","  article_modeled = filt_model.fit_transform(filt_tf_idf)\n","\n","  # Word Scores Dataframe\n","  filt_word_score_df = pd.DataFrame(filt_model.components_, columns=filt_feature_names).T\n","\n","  # Calculated Max score For a Topic and Determines Which Topic a Word Most Closesly it Associates With\n","  filt_word_score_df['Max_score'] = filt_word_score_df.max(axis=1)\n","  filt_word_score_df['Topic_Asoc'] = filt_word_score_df.iloc[:,1:-1].idxmax(axis=1)\n","  filt_word_score_df = filt_word_score_df.sort_values('Max_score', ascending = False).reset_index().rename(columns={'index':'Word'})\n","\n","  filt_word_score_by_topic = []\n","  \n","  # Sorts Word Score DF By Top Word for Each Catagory and Set Col Names\n","  for i in range(filt_word_score_df.shape[1] - 3):\n","    cols = filt_word_score_df[['Word',i]].sort_values(i, ascending = False).reset_index(drop=True)\n","    cols.columns=['Topic ' + str(i) + ' Word', 'Topic ' + str(i) + ' Score']\n","    filt_word_score_by_topic.append(cols)\n","\n","  # Saves Top Words by Topic as DF\n","  filt_word_score_by_topic_df = pd.concat(filt_word_score_by_topic, axis = 1).reset_index().rename(columns={'index':'Rank'})\n","\n","  # Article/Headline Score Dataframe\n","  filt_news_df_select = filt_news_df\n","  filt_article_score_df = pd.concat([filt_news_df_select, pd.DataFrame(article_modeled)], axis=1)\n","\n","  # Calculated Max score For a Topic and Determines Which Topic a Headline Most Closesly it Associates With\n","  filt_article_score_df['Max_score'] = filt_article_score_df.iloc[:,6:].max(axis=1)\n","  filt_article_score_df['Topic_Asoc'] = filt_article_score_df.iloc[:,6:-1].idxmax(axis=1)\n","\n","  #Returns Word Score and Article Score Dataframes\n","  return [filt_word_score_by_topic_df, filt_article_score_df, filt_word_score_df]"],"metadata":{"id":"nr1Iv6Ia7KlI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Runing The NMF Model\n","\n","# dfs_all_year = nmf_by_filter(nun_comp=60)\n","\n","# By Year\n","dfs_2016 = nmf_by_filter(year=2016, nun_comp=50)\n","# dfs_2017 = nmf_by_filter(year=2017, nun_comp=50)\n","# dfs_2018 = nmf_by_filter(year=2018, nun_comp=60)\n","# dfs_2019 = nmf_by_filter(year=2019, nun_comp=40)\n","# dfs_2020 = nmf_by_filter(year=2020, nun_comp=10)"],"metadata":{"id":"T0SQG-JF_kUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfs_2016[0].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"Iejphhdp9Wm3","executionInfo":{"status":"ok","timestamp":1684297840797,"user_tz":420,"elapsed":36,"user":{"displayName":"Irti Haq","userId":"17287341463040515023"}},"outputId":"e8f451e2-2356-48fe-c3cc-e40805c04895"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Rank Topic 0 Word  Topic 0 Score Topic 1 Word  Topic 1 Score Topic 2 Word  \\\n","0     0        trump       5.289210        share       3.646196           us   \n","1     1         poll       0.287683          per       3.481434           st   \n","2     2        would       0.168997     earnings       2.365947         data   \n","3     3        rally       0.149775         loss       1.459404     military   \n","4     4  republicans       0.143753           q2       1.095093        syria   \n","\n","   Topic 2 Score Topic 3 Word  Topic 3 Score Topic 4 Word  ...  Topic 45 Word  \\\n","0       4.503317      clinton       2.900146       profit  ...          world   \n","1       0.250524      hillary       1.323375          net  ...          going   \n","2       0.189681         poll       0.483764           q1  ...         around   \n","3       0.175200        email       0.152101           h1  ...          today   \n","4       0.159704          fbi       0.147285       zlotys  ...       lobbying   \n","\n","  Topic 45 Score  Topic 46 Word Topic 46 Score  Topic 47 Word Topic 47 Score  \\\n","0       2.422052         market       2.398414            bln       1.655838   \n","1       0.912393          could       1.442341          group       1.099958   \n","2       0.809770          stock       0.585244           unit       0.698124   \n","3       0.807451         cramer       0.400677           yuan       0.647842   \n","4       0.244350          rally       0.199455          plans       0.633129   \n","\n","   Topic 48 Word Topic 48 Score  Topic 49 Word Topic 49 Score  \n","0           bill       2.074253         update       2.481521  \n","1         senate       1.067592         growth       0.311746  \n","2         puerto       0.490989       provides       0.184691  \n","3           rico       0.470166  stocksfactors       0.153869  \n","4         energy       0.374910            1uk       0.135340  \n","\n","[5 rows x 101 columns]"],"text/html":["\n","  <div id=\"df-9a329e79-60b2-476e-b946-8f292a665593\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Rank</th>\n","      <th>Topic 0 Word</th>\n","      <th>Topic 0 Score</th>\n","      <th>Topic 1 Word</th>\n","      <th>Topic 1 Score</th>\n","      <th>Topic 2 Word</th>\n","      <th>Topic 2 Score</th>\n","      <th>Topic 3 Word</th>\n","      <th>Topic 3 Score</th>\n","      <th>Topic 4 Word</th>\n","      <th>...</th>\n","      <th>Topic 45 Word</th>\n","      <th>Topic 45 Score</th>\n","      <th>Topic 46 Word</th>\n","      <th>Topic 46 Score</th>\n","      <th>Topic 47 Word</th>\n","      <th>Topic 47 Score</th>\n","      <th>Topic 48 Word</th>\n","      <th>Topic 48 Score</th>\n","      <th>Topic 49 Word</th>\n","      <th>Topic 49 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>trump</td>\n","      <td>5.289210</td>\n","      <td>share</td>\n","      <td>3.646196</td>\n","      <td>us</td>\n","      <td>4.503317</td>\n","      <td>clinton</td>\n","      <td>2.900146</td>\n","      <td>profit</td>\n","      <td>...</td>\n","      <td>world</td>\n","      <td>2.422052</td>\n","      <td>market</td>\n","      <td>2.398414</td>\n","      <td>bln</td>\n","      <td>1.655838</td>\n","      <td>bill</td>\n","      <td>2.074253</td>\n","      <td>update</td>\n","      <td>2.481521</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>poll</td>\n","      <td>0.287683</td>\n","      <td>per</td>\n","      <td>3.481434</td>\n","      <td>st</td>\n","      <td>0.250524</td>\n","      <td>hillary</td>\n","      <td>1.323375</td>\n","      <td>net</td>\n","      <td>...</td>\n","      <td>going</td>\n","      <td>0.912393</td>\n","      <td>could</td>\n","      <td>1.442341</td>\n","      <td>group</td>\n","      <td>1.099958</td>\n","      <td>senate</td>\n","      <td>1.067592</td>\n","      <td>growth</td>\n","      <td>0.311746</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>would</td>\n","      <td>0.168997</td>\n","      <td>earnings</td>\n","      <td>2.365947</td>\n","      <td>data</td>\n","      <td>0.189681</td>\n","      <td>poll</td>\n","      <td>0.483764</td>\n","      <td>q1</td>\n","      <td>...</td>\n","      <td>around</td>\n","      <td>0.809770</td>\n","      <td>stock</td>\n","      <td>0.585244</td>\n","      <td>unit</td>\n","      <td>0.698124</td>\n","      <td>puerto</td>\n","      <td>0.490989</td>\n","      <td>provides</td>\n","      <td>0.184691</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>rally</td>\n","      <td>0.149775</td>\n","      <td>loss</td>\n","      <td>1.459404</td>\n","      <td>military</td>\n","      <td>0.175200</td>\n","      <td>email</td>\n","      <td>0.152101</td>\n","      <td>h1</td>\n","      <td>...</td>\n","      <td>today</td>\n","      <td>0.807451</td>\n","      <td>cramer</td>\n","      <td>0.400677</td>\n","      <td>yuan</td>\n","      <td>0.647842</td>\n","      <td>rico</td>\n","      <td>0.470166</td>\n","      <td>stocksfactors</td>\n","      <td>0.153869</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>republicans</td>\n","      <td>0.143753</td>\n","      <td>q2</td>\n","      <td>1.095093</td>\n","      <td>syria</td>\n","      <td>0.159704</td>\n","      <td>fbi</td>\n","      <td>0.147285</td>\n","      <td>zlotys</td>\n","      <td>...</td>\n","      <td>lobbying</td>\n","      <td>0.244350</td>\n","      <td>rally</td>\n","      <td>0.199455</td>\n","      <td>plans</td>\n","      <td>0.633129</td>\n","      <td>energy</td>\n","      <td>0.374910</td>\n","      <td>1uk</td>\n","      <td>0.135340</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 101 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a329e79-60b2-476e-b946-8f292a665593')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9a329e79-60b2-476e-b946-8f292a665593 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9a329e79-60b2-476e-b946-8f292a665593');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["dfs_2016[1].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"4ivK_1FA9Zyv","executionInfo":{"status":"ok","timestamp":1684297840797,"user_tz":420,"elapsed":33,"user":{"displayName":"Irti Haq","userId":"17287341463040515023"}},"outputId":"19cab50a-1d15-4f7b-8ede-feb054ceced9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  date  year  month  day  \\\n","0  2016-09-15 16:46:51  2016    9.0   15   \n","1           2016-03-14  2016    3.0   14   \n","2           2016-12-11  2016   12.0   11   \n","3  2016-01-22 04:46:03  2016    1.0   22   \n","4  2016-08-20 00:00:00  2016    8.0   20   \n","\n","                                               title         publication  \\\n","0                       albariño wine forget context  The New York Times   \n","1       cramer gw pharma finds oxycodone replacement                CNBC   \n","2  briefblue sky alternative investments says us ...             Reuters   \n","3                    ‘liberty coercion’ gary gerstle  The New York Times   \n","4  white may saved florida faceeating suspect sho...           Vice News   \n","\n","          0         1         2         3  ...   42        43        44  \\\n","0  0.000000  0.000099  0.000210  0.000000  ...  0.0  0.000028  0.000000   \n","1  0.000000  0.000255  0.000211  0.000138  ...  0.0  0.000000  0.000000   \n","2  0.000000  0.000000  0.032761  0.000000  ...  0.0  0.003631  0.000002   \n","3  0.000045  0.000000  0.000000  0.000020  ...  0.0  0.000142  0.000388   \n","4  0.000000  0.000000  0.000000  0.000000  ...  0.0  0.000000  0.000180   \n","\n","         45        46        47        48        49  Max_score  Topic_Asoc  \n","0  0.000158  0.000008  0.000118  0.000000  0.000349   0.000491          27  \n","1  0.001274  0.014798  0.002757  0.000028  0.000077   0.014798          46  \n","2  0.000000  0.000000  0.002526  0.000000  0.000354   0.052237           5  \n","3  0.000107  0.000245  0.000000  0.001684  0.000000   0.001684          48  \n","4  0.000000  0.000000  0.000000  0.000000  0.000000   0.107330          36  \n","\n","[5 rows x 58 columns]"],"text/html":["\n","  <div id=\"df-58cd7bdd-eafe-4766-b68b-61d60fe0c3b4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>day</th>\n","      <th>title</th>\n","      <th>publication</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>...</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>Max_score</th>\n","      <th>Topic_Asoc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2016-09-15 16:46:51</td>\n","      <td>2016</td>\n","      <td>9.0</td>\n","      <td>15</td>\n","      <td>albariño wine forget context</td>\n","      <td>The New York Times</td>\n","      <td>0.000000</td>\n","      <td>0.000099</td>\n","      <td>0.000210</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000028</td>\n","      <td>0.000000</td>\n","      <td>0.000158</td>\n","      <td>0.000008</td>\n","      <td>0.000118</td>\n","      <td>0.000000</td>\n","      <td>0.000349</td>\n","      <td>0.000491</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2016-03-14</td>\n","      <td>2016</td>\n","      <td>3.0</td>\n","      <td>14</td>\n","      <td>cramer gw pharma finds oxycodone replacement</td>\n","      <td>CNBC</td>\n","      <td>0.000000</td>\n","      <td>0.000255</td>\n","      <td>0.000211</td>\n","      <td>0.000138</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.001274</td>\n","      <td>0.014798</td>\n","      <td>0.002757</td>\n","      <td>0.000028</td>\n","      <td>0.000077</td>\n","      <td>0.014798</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2016-12-11</td>\n","      <td>2016</td>\n","      <td>12.0</td>\n","      <td>11</td>\n","      <td>briefblue sky alternative investments says us ...</td>\n","      <td>Reuters</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.032761</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.003631</td>\n","      <td>0.000002</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.002526</td>\n","      <td>0.000000</td>\n","      <td>0.000354</td>\n","      <td>0.052237</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2016-01-22 04:46:03</td>\n","      <td>2016</td>\n","      <td>1.0</td>\n","      <td>22</td>\n","      <td>‘liberty coercion’ gary gerstle</td>\n","      <td>The New York Times</td>\n","      <td>0.000045</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000020</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000142</td>\n","      <td>0.000388</td>\n","      <td>0.000107</td>\n","      <td>0.000245</td>\n","      <td>0.000000</td>\n","      <td>0.001684</td>\n","      <td>0.000000</td>\n","      <td>0.001684</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2016-08-20 00:00:00</td>\n","      <td>2016</td>\n","      <td>8.0</td>\n","      <td>20</td>\n","      <td>white may saved florida faceeating suspect sho...</td>\n","      <td>Vice News</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000180</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.107330</td>\n","      <td>36</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 58 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58cd7bdd-eafe-4766-b68b-61d60fe0c3b4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-58cd7bdd-eafe-4766-b68b-61d60fe0c3b4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-58cd7bdd-eafe-4766-b68b-61d60fe0c3b4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["dfs_2016[2].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"FV_cbZgi9dic","executionInfo":{"status":"ok","timestamp":1684297840798,"user_tz":420,"elapsed":32,"user":{"displayName":"Irti Haq","userId":"17287341463040515023"}},"outputId":"7db871fb-0a9f-4f27-a797-9fdd2820a1e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Word        0    1    2    3    4    5    6    7    8  ...        42  \\\n","0     win  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n","1     big  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n","2     gop  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n","3  debate  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n","4   trump  5.28921  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.001589   \n","\n","    43        44   45   46   47   48   49  Max_score  Topic_Asoc  \n","0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0   6.864115          11  \n","1  0.0  0.003177  0.0  0.0  0.0  0.0  0.0   6.255719          11  \n","2  0.0  0.000000  0.0  0.0  0.0  0.0  0.0   5.843846          17  \n","3  0.0  0.000000  0.0  0.0  0.0  0.0  0.0   5.416019          18  \n","4  0.0  0.001213  0.0  0.0  0.0  0.0  0.0   5.289210          15  \n","\n","[5 rows x 53 columns]"],"text/html":["\n","  <div id=\"df-fb968a86-0571-45c7-81bf-c4d532d732f9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>...</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>Max_score</th>\n","      <th>Topic_Asoc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>win</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.864115</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>big</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.003177</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.255719</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gop</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.843846</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>debate</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.416019</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>trump</td>\n","      <td>5.28921</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.001589</td>\n","      <td>0.0</td>\n","      <td>0.001213</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5.289210</td>\n","      <td>15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 53 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb968a86-0571-45c7-81bf-c4d532d732f9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fb968a86-0571-45c7-81bf-c4d532d732f9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fb968a86-0571-45c7-81bf-c4d532d732f9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#@title Saving Model Dataframes as Pickle Files\n","\n","\"\"\"\n","dfs_2016[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2016_df.pkl\")\n","dfs_2017[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2017_df.pkl\")\n","dfs_2018[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2018_df.pkl\")\n","dfs_2019[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2019_df.pkl\")\n","dfs_2020[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2020_df.pkl\")\n","\n","dfs_2016[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_2016_df.pkl\")\n","dfs_2017[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2017.pkl\")\n","dfs_2018[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2018.pkl\")\n","dfs_2019[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2019.pkl\")\n","dfs_2020[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2020.pkl\")\n","\n","dfs_all_year[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_all_year_df.pkl\")\n","dfs_all_year[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_all_year_df.pkl\")\n","\"\"\""],"metadata":{"id":"MdQ15caWWtLD","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1684297840799,"user_tz":420,"elapsed":32,"user":{"displayName":"Irti Haq","userId":"17287341463040515023"}},"outputId":"55538d57-f1ba-446e-b9f6-5fbf042d8029"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndfs_2016[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2016_df.pkl\")\\ndfs_2017[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2017_df.pkl\")\\ndfs_2018[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2018_df.pkl\")\\ndfs_2019[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2019_df.pkl\")\\ndfs_2020[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_2020_df.pkl\")\\n\\ndfs_2016[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_2016_df.pkl\")\\ndfs_2017[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2017.pkl\")\\ndfs_2018[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2018.pkl\")\\ndfs_2019[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2019.pkl\")\\ndfs_2020[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_df_2020.pkl\")\\n\\ndfs_all_year[0].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/word_score_all_year_df.pkl\")\\ndfs_all_year[1].to_pickle(\"/content/drive/MyDrive/CSE 412 Group Project/Data/aricle_score_all_year_df.pkl\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]}]}